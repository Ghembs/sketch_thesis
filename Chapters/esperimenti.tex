\myChapter{Esperimenti}
\section{Introduzione} % (fold)
\label{sec:introduzione}
In questo elaborato si è scelto di riprodurre ed analizzare i risultati presentati da Ha e Eck attraverso tre esperimenti: nel primo è stata scelta la configurazione standard del modello, con un VAE completo e layer LSTM sia nell'encoder che nel decoder, la rete è stata addestrata su due dataset: \textit{cat.npz} (gatti) e \textit{flying\_saucer.npz} (dischi volanti). Nel secondo è stata scelta la configurazione con il solo decoder, utilizzato come modello autoregressivo non condizionato ad una variabile latente (con i pesi inizializzati a zero), in questo caso il layer utilizzato è HyperLSTM\footnote{Questo layer non è stato approfondito nell'introduzione di questo elaborato, si rimanda a \cite{hyperlstm} per ulteriori informazioni.}, che eccelle nella generazione di sequenze, il dataset è stato addestrato sul solo dataset \textit{owl.npz} (gufi), infine è stato addestrato un modello con \textit{Layer Normalization} nell'encoder e HyperLSTM nel decoder\footnote{Soluzione suggerita in \url{https://github.com/tensorflow/magenta/tree/master/magenta/models/sketch_rnn}}, per poter gestire un ampio training set composto da tre categorie: \textit{elephant} (elefanti), \textit{hat} (cappelli) e \textit{snake} serpenti\footnote{In omaggio a \cite{petitprince}}. Di seguito verranno illustrate e confrontate le reti neurali prodotte da queste configurazioni, inoltre verranno mostrate alcune immagini generate tramite diversi approcci che mostreranno la capacità del modello di concettualizzare le proprietà di un disegno.

\begin{minipage}{\linewidth}
\begin{lstlisting}[language = Python, frame = single, caption = {Iperparametri standard di sketch-rnn}, label = {iperparametri}, captionpos = b, basicstyle=\scriptsize]
num_steps=10000000,            # Total number of training set. Keep large.
save_every=500,                # Number of batches per checkpoint creation.
dec_rnn_size=512,              # Size of decoder.
dec_model='lstm',              # Decoder: lstm, layer_norm or hyper.
enc_rnn_size=256,              # Size of encoder.
enc_model='lstm',              # Encoder: lstm, layer_norm or hyper.
z_size=128,                    # Size of latent vector z. Rec. 32, 64 or 128.
kl_weight=0.5,                 # KL weight of loss. Recommend 0.5 or 1.0.
kl_weight_start=0.01,          # KL start weight when annealing.
kl_tolerance=0.2,              # Level of KL loss at which to stop optimizing
batch_size=100,                # Minibatch size. Recommend leaving at 100.
grad_clip=1.0,                 # Gradient clipping. Recommend leaving at 1.0.
num_mixture=20,                # Number of mixtures in Gaussian mixture model.
learning_rate=0.001,           # Learning rate.
decay_rate=0.9999,             # Learning rate decay per minibatch.
kl_decay_rate=0.99995,         # KL annealing decay rate per minibatch.
min_learning_rate=0.00001,     # Minimum learning rate.
use_recurrent_dropout=True,    # Recurrent Dropout without Memory Loss.
recurrent_dropout_prob=0.90,   # Probability of recurrent dropout keep.
use_input_dropout=False,       # Input dropout. Recommend leaving False.
input_dropout_prob=0.90,       # Probability of input dropout keep.
use_output_dropout=False,      # Output droput. Recommend leaving False.
output_dropout_prob=0.90,      # Probability of output dropout keep.
random_scale_factor=0.15,      # Random scaling data augmention proportion.
augment_stroke_prob=0.10,      # Point dropping augmentation proportion.
conditional=True,              # If False, use decoder-only model.
\end{lstlisting}
\end{minipage}
In questa sezione di codice sono mostrati gli iperparametri del modello, coi loro valori di default. Si può notare che \textit{N\textsubscript{z}} = 128 e che decoder e encoder sono simmetrici\footnote{Si ricordi che l'encoder è un layer bidirezionale, di conseguenza la dimensione dello stato finale, dopo la concatenazione, risulta essere 512.}. A partire da questi valori, viene assemblata la rete neurale mostrata in tabella \ref{tab:1}.
\begin{table}[ht]
	\centering
	\begin{tabular}{ccc}
		\hline
		\hline
		Layer & Output shape & Variabili addestrabili \\
		\hline
		\hline
		Input & (?, 250, 5) & 0 \\
		\hline
		Forward LSTM & (?, 256) & 268288 \\
		\hline
		Backward LSTM & (?, 256) & 268288 \\
		\hline
		Mu & (?, 128) & 65664 \\
		\hline
		Log Sigma & (?, 128) & 65664 \\
		\hline
		State initializer & (?, 1024) & 132096 \\
		\hline
		Decoder LSTM & (?, 512) & 1323008 \\
		\hline
		Output & (?, 123) & 63099 \\
		\hline
		\hline
		\multicolumn{3}{c}{Numero di variabili totale: 2186107} \\
		\hline
		\hline
	\end{tabular}
	\caption{I layer ottenuti attraverso la configurazione standard.}
	\label{tab:2}
\end{table}

Nel caso della seconda rete la dimensione del layer ricorrente è sempre 512 ma, per la maggior complessità dei parametri interni, si ottiene una rete com 2218363 variabili addestrabili. L'ultimo modello, infine, presenta 24515195 variabili addestrabili con la dimensione dell'output del decoder pari a 2048 e quella dell'encoder pari a 512 (1024)\footnote{Si omette la tabella, riportando solo le dimensioni fondamentali, per la complessità di lettura derivante dalla struttura dell'HyperLSTM.}.

Con queste reti sono stati condotti vari esperimenti, in particolare: nei modelli condizionali sono state svolte interpolazioni nello spazio di latenza, sia all'interno di una singola classe sia fra classi diverse, inoltre è stato osservato l'esito della variazione del parametro di temperatura sia su interpolazioni che su generazioni condizionali semplici ed in special modo nel modello autoregressivo, sul quale ha un impatto rilevante.
Di seguito i test effettuati saranno illustrati in dettaglio e commentati.
\section{Generazione condizionale} % (fold)
\label{sec:generazione_condizionale}
In questa sezione vengono valutati i disegni ricostruiti \textit{S'}, dato in input un disegno \textit{S}, da parte dei due VAE.
\begin{figure}[ht]
	\centering
	\begin{tabular}{cccc}
		\fbox{\includegraphics[width=0.2\linewidth]{img/cat_enc.png}} &
		\includegraphics[width=0.2\linewidth]{img/cat_dec_0.png} &
		\includegraphics[width=0.2\linewidth]{img/cat_dec_2.png} &
		\includegraphics[width=0.2\linewidth]{img/cat_dec_3.png} \\
		\includegraphics[width=0.2\linewidth]{img/cat_dec_4.png} &
		\includegraphics[width=0.2\linewidth]{img/cat_dec_5.png} &
		\includegraphics[width=0.2\linewidth]{img/cat_dec_6.png} &
		\includegraphics[width=0.2\linewidth]{img/cat_dec_7.png}
	\end{tabular}
	\caption{La prima immagine è estratta dal dataset, le altre sono immagini originali generate dal modello standard}
	\label{fig:1.17}
\end{figure}
Questo primo esempio \ref{fig:1.17} illustra un risultato semplice, quanto interessante: la figura nel riquadro è stata passata come input alla prima rete neurale, le successive sono immagini generate dalla rete attraverso un parametro di temperatura di 0.8, condizionate allo stesso input. L'ampiezza del parametro di temperatura permette alla rete una maggiore libertà \ref{sec:modello}, aumentando la varianza sull'offset dei punti\footnote{Al prezzo di immagini maggiormente confuse.}, il che mostra le potenzialità del modello nel creare sketch simili ma unici ed originali, a partire da un singolo input.

Il modello è anche in grado di reinterpretare un disegno proveniente da una classe qualunque, secondo le caratteristiche su cui è stato addestrato. Se infatti alla rete viene chiesto di riprodurre dati da una classe che non conosce, questa produrrà sketch che combineranno proprietà dovute al condizionamento con le proprietà dovute all'apprendimento, talvolta aggiungendo dettagli, talvolta distorcendo le strutture date.
\subsection{Variazioni di temperatura} % (fold)
\label{sub:variazioni_di_temperatura}
Come detto in precedenza \ref{sec:modello}, nell'operazione di campionamento di un disegno viene introdotto un parametro $\tau$ il cui scopo è contenere la variabilità dell'offset e dei parametri categorici. La variazione di questo parametro, generando schizzi condizionati dallo stesso disegno di partenza, porta ad output che vanno da una riproduzione più fedele dell'input ad una più fantasiosa.

Anche in questo caso è interessante osservare come ciò si rifletta sui tentativi della rete di interpretare oggetti sconosciuti secondo le proprie categorie. Di fatto in questa situazione il parametro di temperatura diventa il peso assegnato alle nuove caratteristiche osservate, con un parametro più basso che obbliga il VAE ad attenersi il più possibile alle proprietà dell'input.
% subsection variazioni_di_temperatura (end)
\subsection{Interpolazioni} % (fold)
\label{sub:interpolazioni}
Interpolando fra vettori latenti è possibile visualizzare come un'immagine muta in un'altra, osservando la ricostruzione dell'interpolazione. Considerato che sullo spazio di latenza viene forzata una Gaussiana come distribuzione a priori, è lecito aspettarsi una mutazione più fluida e priva di "salti" nello spazio fra due vettori di latenza diversi. Un modello addestrato col parametro del peso della divergenza KL ($w_KL$ \ref{sub:training}) posto ad un valore alto dovrebbe produrre immagini più aderenti ai dati, dato un vettore di latenza $\boldsymbol{z}$ interpolato sfericamente, rispetto ad una rete addestrata con un valore di $w_KL$ più basso.

Per dimostrare questo risultato è sufficiente addestrare diversi modelli sugli stessi dataset, utilizzando valori diversi di $w_KL$. Si riporta l'esperimento svolto da Ha e Eck sui dataset \textit{cat} e \textit{pigs}.
% subsection interpolazioni (end)
\subsection{Analogie fra disegni} % (fold)
\label{sub:analogie_fra_disegni}
L'esempio di interpolazione in fig. suggerisce che il vettore di latenza $\boldsymbol{z}$ codifichi caratteristiche concettuali di un disegno. Modelli addestrati con un minor peso alla divergenza KL, sono in grado di incrementare i dettagli di uno sketch con caratteristiche prese da un altro, ad esempio aggiungendo un corpo ad una testa di gatto, acquisendolo dal disegno di un maiale. Questo è possibile perché lo spazio di latenza è abbastanza "rilassato" da permettere che ogni vettore interpolato fra due vettori di latenza risulti in un disegno coerente, ciò permette di eseguire operazioni aritmetiche fra vettori ottenuti da diversi disegni ed esplorare come il modello organizzi lo spazio latente per rappresentare i concetti nella moltitudine degli sketch generati.

Nello specifico della figura: è stato sottratto il vettore latente codificante la testa di un maiale da quello che codifica un maiale intero, ciò ha portato ad un vettore contenente le caratteristiche di un corpo. Aggiungendo questa differenza al vettore che rappresenta la testa di un gatto è stato ottenuto un gatto completo. Allo stesso modo è stato rimosso il corpo di un maiale ottenendo prima la codifica tramite gatti.
% subsection analogie_fra_disegni (end)
% section generazione_condizionale (end)
\section{Generazione non condizionale} % (fold)
\label{sec:generazione_non_condizionale}
Come caso particolare, è possibile addestrare il modello per generare disegni non condizionati ad un input, è il caso della terza rete che è stata assemblata per gli esperimenti di questo elaborato. Rimuovendo l'encoder si ottiene un modello autoregressivo privo di variabile latente, di conseguenza gli stati iniziali e delle celle vengono inizializzati a zero. Gli input $x_i$ della RNN ad ogni time step sono solo $s_{i-1}$ o $S{i-1}'$ dato che non c'è nessun vettore da concatenare. Con questa struttura è stata sperimentata la generazione al variare del parametro di temperatura.
\begin{figure}[ht]
	\centering
	\begin{tabular}{c}
		\includegraphics[width=\linewidth]{img/owl_temp_02.png} \\
		\includegraphics[width=\linewidth]{img/owl_temp_04.png} \\
		\includegraphics[width=\linewidth]{img/owl_temp_05.png} \\
		\includegraphics[width=\linewidth]{img/owl_temp_06.png} \\
		\includegraphics[width=\linewidth]{img/owl_temp_08.png} \\
		\includegraphics[width=\linewidth]{img/owl_temp_1.png}
	\end{tabular}
	\caption{Immagini generate dal modello autoregressivo al variare del parametro di temperatura}
\end{figure}

Si può notare come la mancanza di uno spazio di latenza a cui condizionare l'output renda preminente l'impatto della variazione della temperatura sulla variabilità dei disegni generati: al crescere del parametro la rete passa da disegni estremamente fedeli ed accurati a disegni molto più vaghi ed imprecisi.

\subsection{Predire il finale di un disegno incompleto} % (fold)
\label{sub:predire_il_finale_di_un_disegno_incompleto}
Un'interessante applicazione pratica della variante con il solo decoder è che rende possibile utilizzare \texttt{sketch-rnn} per offrire spunti artistici, completando sketch in input. Il layer ricorrente della rete viene utilizzato in un primo momento per generare una codifica della porzione di disegno ricevuta in input, ottenendo un hidden state condizionato ad esso. Successivamente lo stato generato viene utilizzato per inizializzare nuovamente la rete, che proseguirà l'esecuzione fino in fondo, completando la sequenza a partire da quella data.
% subsection predire_il_finale_di_un_disegno_incompleto (end)
% section generazione_non_condizionale (end)

\begin{minipage}{\linewidth}
\begin{lstlisting}[language = Python, frame = single, caption = {}, captionpos = b]

\end{lstlisting}
\end{minipage}